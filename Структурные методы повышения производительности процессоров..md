#### 1. Увеличение быстродействия элементов (тактовой частоты) 
#### 2. Изменение алгоритмов обработки, т.е. совершенствование алгоритмов 
#### 3. Распараллеливание 

***В общем плане под параллельными вычислениями понимаются процессы обработки данных, в которых одновременно могут выполняться нескольких машинных операций. Достижение параллелизма возможно только при выполнимости следующих требований к архитектурным принципам построения вычислительной системы:***
● **Независимость функционирования отдельных устройств ЭВМ** данное требование относится в равной степени ко всем основным компонентам вычислительной системы- к устройствам ввода-вывода, к обрабатывающим процессорам и к устройствам памяти;    
● **Избыточность элементов вычислительной системы**- организация избыточности может осуществляться в следующих основных формах: 
	1. использование специализированных устройств таких, например, как отдельных процессоров для целочисленной и вещественной арифметики, устройств многоуровневой памяти (регистры, кэш); 
	2. дублирование устройств ЭВМ путем использования, например, нескольких однотипных обрабатывающих процессоров или нескольких устройств оперативной памяти. 

#### **Изменение структуры исполнительной части схемы.**

**С точки зрения структурной организации возможны два пути повышения производительности**
1. распараллеливание во времени (конвейер). Т. 
2. распараллеливание в пространстве (использование нескольких однотипных устройств для решения одной задачи). 

Любое распараллеливание требует организацию устройства в виде системы , состоящей из набора функциональных модулей способных работать независимо друг от друга. Максимальная производительность будет достигаться при полной одновременной загрузке всех модулей без простоев.
Конвейер - наиболее простая идея. Для этого необходимо разделить задачу на ряд этапов Схему необходимо построить таким образом, чтобы решение происходило независимо и параллельно. 
Рассмотрим самый простой пример. Для простого процессора можно выделить два этапа: 
1. чтение команды 
2. выполнение команды. 

![[7.1.png]]

В конвейере будет выполняться чтение следующей команды и выполнение предыдущей

![[7.2.png]]

### ***Deepseek:***

Структурные методы повышения производительности процессоров направлены на оптимизацию внутренней архитектуры и организации вычислений. Они позволяют увеличить скорость выполнения команд, улучшить параллелизм и эффективно использовать ресурсы процессора.  

#### **Основные структурные методы:**  

#### 1. Конвейеризация (Pipelining)
- Разбиение выполнения команды на несколько этапов (выборка, декодирование, выполнение, запись).  
- Позволяет одновременно обрабатывать несколько команд на разных стадиях.  
- **Проблемы:** конфликты (структурные, управляющие, по данным).  

#### 2. Суперскалярная архитектура  
- Наличие нескольких исполнительных устройств (АЛУ, FPU, LSU).  
- Параллельное выполнение нескольких команд за такт (ILP — Instruction-Level Parallelism).  
- **Примеры:** Intel Hyper-Threading, ARM Cortex.  

#### 3. Внеочередное исполнение (Out-of-Order Execution, OoOE)  
- Динамическое переупорядочивание команд для минимизации простоев.  
- Использует **буфер переупорядочивания (ROB)** и **алгоритмы предсказания зависимостей**
- **Примеры:** современные x86 (Intel, AMD), ARM Cortex-A.  

#### 4. Спекулятивное исполнение (Speculative Execution)  
- Предвыполнение команд до разрешения условных переходов.  
- При ошибке предсказания — откат (штраф за misprediction).  
- **Примеры:** Branch Prediction, Intel’s Branch Target Buffer (BTB).  

#### 5. Увеличение тактовой частоты и разрядности 
- Повышение частоты (но ограничено тепловыделением и физическими пределами).  
- Увеличение разрядности (32 → 64 бит) для работы с большими числами и памятью.  

#### 6. Кэширование памяти  
- Многоуровневая кэш-память (L1, L2, L3) для уменьшения задержек доступа.  
- Оптимизация алгоритмов предвыборки (prefetching).  

#### 7. SIMD-обработка (Single Instruction Multiple Data) 
- Векторные вычисления (одна команда — много данных).  
- **Примеры:** SSE, AVX (x86), NEON (ARM).  

#### 8. Многоядерность (Chip Multi-Processing, CMP)  
- Несколько ядер на одном кристалле (параллелизм на уровне потоков — TLP).  
- **Примеры:** multi-core CPUs (Intel Core i7, AMD Ryzen).  

#### 9. Гетерогенные вычисления  
- Совместное использование CPU, GPU, AI-ускорителей.  
- **Примеры:** ARM big.LITTLE, Apple M1/M2, NVIDIA Grace Hopper.  

#### 10. Оптимизация энергопотребления (DVFS, Power Gating)  
- Динамическое изменение напряжения и частоты (Dynamic Voltage and Frequency Scaling).  
- Отключение неиспользуемых блоков (Power Gating).  

#### **Заключение** 
Современные процессоры используют комбинацию этих методов для достижения высокой производительности при ограничениях энергопотребления и тепловыделения. Дальнейшее развитие связано с 3D-чипами (Chiplet-архитектура), квантовыми и нейроморфными вычислениями.